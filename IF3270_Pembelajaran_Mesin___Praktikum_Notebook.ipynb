{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR1JW69eLfG_"
      },
      "source": [
        "# IF3270 Machine Learning | Praktikum\n",
        "\n",
        "This notebook serves as a template for the assignment. Please create a copy of this notebook to complete your work. You can add more code blocks, markdown blocks, or new sections if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucbaI5rBLtjJ"
      },
      "source": [
        "Group Number: xx\n",
        "\n",
        "Group Members:\n",
        "- Name (NIM)\n",
        "- Name (NIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzsfETHLfHA"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jZJU5W_4LfHB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import other libraries if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbjLIdYLfHC"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IWFJ-gdLfHD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Ever_Married</th>\n",
              "      <th>Age</th>\n",
              "      <th>Graduated</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Spending_Score</th>\n",
              "      <th>Family_Size</th>\n",
              "      <th>Var_1</th>\n",
              "      <th>Segmentation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>464198</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>49</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>464238</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>87</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Doctor</td>\n",
              "      <td>0.0</td>\n",
              "      <td>High</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>461219</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>28</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>466979</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>39</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Homemaker</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Average</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_3</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>464835</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>19</td>\n",
              "      <td>No</td>\n",
              "      <td>Healthcare</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Cat_4</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>465738</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>38</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Cat_3</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>460095</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>74</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>460309</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>28</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Cat_7</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>467503</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>26</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Artist</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>465879</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>39</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Artist</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Cat_6</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
              "0  464198    Male          Yes   49       Yes  Entertainment              1.0   \n",
              "1  464238    Male          Yes   87       Yes         Doctor              0.0   \n",
              "2  461219  Female           No   28       Yes     Healthcare              8.0   \n",
              "3  466979  Female          Yes   39       Yes      Homemaker              NaN   \n",
              "4  464835    Male          Yes   19        No     Healthcare              1.0   \n",
              "5  465738    Male           No   38       Yes  Entertainment              8.0   \n",
              "6  460095  Female          Yes   74       Yes  Entertainment              1.0   \n",
              "7  460309    Male           No   28       Yes      Marketing              9.0   \n",
              "8  467503    Male           No   26       Yes         Artist              1.0   \n",
              "9  465879    Male           No   39       Yes         Artist              0.0   \n",
              "\n",
              "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
              "0            Low          2.0  Cat_6            A  \n",
              "1           High          2.0  Cat_6            A  \n",
              "2            Low          3.0  Cat_6            D  \n",
              "3        Average          1.0  Cat_3            A  \n",
              "4            Low          6.0  Cat_4            D  \n",
              "5            Low          2.0  Cat_3            B  \n",
              "6            Low          1.0  Cat_6            C  \n",
              "7            Low          5.0  Cat_7            D  \n",
              "8            Low          4.0  Cat_6            C  \n",
              "9            Low          1.0  Cat_6            A  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train\n",
        "url = \"Train_processed.csv\"\n",
        "# Test\n",
        "url_test = \"test_processed_no_solution.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df_test = pd.read_csv(url_test)\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdSor5sdIYGs"
      },
      "source": [
        "# 1. Exploratory Data Analysis\n",
        "\n",
        "Exploratory Data Analysis (EDA) is a crucial step in the data analysis process that involves examining and visualizing data sets to uncover patterns, trends, anomalies, and insights. It is the first step before applying more advanced statistical and machine learning techniques. EDA helps you to gain a deep understanding of the data you are working with, allowing you to make informed decisions and formulate hypotheses for further analysis. Provide at least 3 analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGiGPVYNIoWk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5647.000000</td>\n",
              "      <td>5647.000000</td>\n",
              "      <td>5085.000000</td>\n",
              "      <td>5423.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>463474.687799</td>\n",
              "      <td>43.663538</td>\n",
              "      <td>2.654277</td>\n",
              "      <td>2.861147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2598.820204</td>\n",
              "      <td>16.779417</td>\n",
              "      <td>3.429239</td>\n",
              "      <td>1.536501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>458982.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>461248.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>463468.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>465754.500000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>467974.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ID          Age  Work_Experience  Family_Size\n",
              "count    5647.000000  5647.000000      5085.000000  5423.000000\n",
              "mean   463474.687799    43.663538         2.654277     2.861147\n",
              "std      2598.820204    16.779417         3.429239     1.536501\n",
              "min    458982.000000    16.000000         0.000000     1.000000\n",
              "25%    461248.500000    30.000000         0.000000     2.000000\n",
              "50%    463468.000000    41.000000         1.000000     3.000000\n",
              "75%    465754.500000    53.000000         4.000000     4.000000\n",
              "max    467974.000000    91.000000        14.000000     9.000000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write your code here\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Gender               0\n",
              "Ever_Married        84\n",
              "Age                  0\n",
              "Graduated           40\n",
              "Profession          79\n",
              "Work_Experience    562\n",
              "Spending_Score       0\n",
              "Family_Size        224\n",
              "Var_1               53\n",
              "Segmentation         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Work_Experience</th>\n",
              "      <th>Family_Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5647.000000</td>\n",
              "      <td>5647.000000</td>\n",
              "      <td>5085.000000</td>\n",
              "      <td>5423.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>463474.687799</td>\n",
              "      <td>43.663538</td>\n",
              "      <td>2.654277</td>\n",
              "      <td>2.861147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2598.820204</td>\n",
              "      <td>16.779417</td>\n",
              "      <td>3.429239</td>\n",
              "      <td>1.536501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>458982.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>461248.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>463468.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>465754.500000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>467974.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ID          Age  Work_Experience  Family_Size\n",
              "count    5647.000000  5647.000000      5085.000000  5423.000000\n",
              "mean   463474.687799    43.663538         2.654277     2.861147\n",
              "std      2598.820204    16.779417         3.429239     1.536501\n",
              "min    458982.000000    16.000000         0.000000     1.000000\n",
              "25%    461248.500000    30.000000         0.000000     2.000000\n",
              "50%    463468.000000    41.000000         1.000000     3.000000\n",
              "75%    465754.500000    53.000000         4.000000     4.000000\n",
              "max    467974.000000    91.000000        14.000000     9.000000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "Best Hyperparameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
            "Best Model Accuracy: 0.5407\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    \"classifier__n_estimators\": [50, 100, 200],  # Number of trees\n",
        "    \"classifier__max_depth\": [None, 10, 20],  # Depth of trees\n",
        "    \"classifier__min_samples_split\": [2, 5, 10],  # Min samples to split\n",
        "    \"classifier__min_samples_leaf\": [1, 2, 4]  # Min samples per leaf\n",
        "}\n",
        "\n",
        "# Grid Search with 5-fold CV\n",
        "grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best model from GridSearch\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Best Model Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID                   int64\n",
            "Gender              object\n",
            "Ever_Married        object\n",
            "Age                  int64\n",
            "Graduated           object\n",
            "Profession          object\n",
            "Work_Experience    float64\n",
            "Spending_Score      object\n",
            "Family_Size        float64\n",
            "Var_1               object\n",
            "Segmentation        object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvx-gT3bLfHM"
      },
      "source": [
        "# 2. Split Training Set and Validation Set\n",
        "\n",
        "Splitting the training and validation set works as an early diagnostic towards the performance of the model we train. This is done before the preprocessing steps to **avoid data leakage inbetween the sets**. If you want to use k-fold cross-validation, split the data later and do the cleaning and preprocessing separately for each split.\n",
        "\n",
        "Note: For training, you should use the data contained in the `Train_processed.csv` given by the TA. The `test_processed_no_solution.csv` data is only used for kaggle submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4yWCUFFBLfHM"
      },
      "outputs": [],
      "source": [
        "# Split training set and validation set here, store into variables train_set and val_set.\n",
        "# Remember to also keep the original training set before splitting. This will come important later.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "target_variable = 'Segmentation'\n",
        "X = df.drop(columns=[target_variable]) # Input features\n",
        "y = df[target_variable] # Output feature\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC14lmo_LfHN"
      },
      "source": [
        "# 3. Data Cleaning and Preprocessing\n",
        "\n",
        "This step is the first thing to be done once a Data Scientist have grasped a general knowledge of the data. Raw data is **seldom ready for training**, therefore steps need to be taken to clean and format the data for the Machine Learning model to interpret.\n",
        "\n",
        "By performing data cleaning and preprocessing, you ensure that your dataset is ready for model training, leading to more accurate and reliable machine learning results. These steps are essential for transforming raw data into a format that machine learning algorithms can effectively learn from and make predictions.\n",
        "\n",
        "For each step that you will do, **please explain the reason why did you do that process. Write it in a markdown cell under the code cell you wrote.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5rksSMAWICY_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset (assuming df is already loaded)\n",
        "if \"ID\" in df.columns:\n",
        "    df = df.drop(columns=[\"ID\"])\n",
        "\n",
        "# Identifying feature types\n",
        "num_features = [\"Age\", \"Work_Experience\", \"Family_Size\"]\n",
        "cat_features = [\"Gender\", \"Ever_Married\", \"Graduated\", \"Profession\", \"Spending_Score\", \"Var_1\"]\n",
        "\n",
        "# Creating preprocessing steps\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ctVzt5DLfHd"
      },
      "source": [
        "# Compile Preprocessing Pipeline\n",
        "\n",
        "All of the preprocessing classes or functions defined earlier will be compiled in this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZlncSVjJG6"
      },
      "source": [
        "If you use sklearn to create preprocessing classes, you can list your preprocessing classes in the Pipeline object sequentially, and then fit and transform your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jHraoW_7LfHd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num__Age</th>\n",
              "      <th>num__Work_Experience</th>\n",
              "      <th>num__Family_Size</th>\n",
              "      <th>cat__Gender_Female</th>\n",
              "      <th>cat__Gender_Male</th>\n",
              "      <th>cat__Ever_Married_No</th>\n",
              "      <th>cat__Ever_Married_Yes</th>\n",
              "      <th>cat__Graduated_No</th>\n",
              "      <th>cat__Graduated_Yes</th>\n",
              "      <th>cat__Profession_Artist</th>\n",
              "      <th>...</th>\n",
              "      <th>cat__Spending_Score_Average</th>\n",
              "      <th>cat__Spending_Score_High</th>\n",
              "      <th>cat__Spending_Score_Low</th>\n",
              "      <th>cat__Var_1_Cat_1</th>\n",
              "      <th>cat__Var_1_Cat_2</th>\n",
              "      <th>cat__Var_1_Cat_3</th>\n",
              "      <th>cat__Var_1_Cat_4</th>\n",
              "      <th>cat__Var_1_Cat_5</th>\n",
              "      <th>cat__Var_1_Cat_6</th>\n",
              "      <th>cat__Var_1_Cat_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.318064</td>\n",
              "      <td>-0.452603</td>\n",
              "      <td>-0.575536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.582944</td>\n",
              "      <td>-0.756436</td>\n",
              "      <td>-0.575536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.933580</td>\n",
              "      <td>1.674232</td>\n",
              "      <td>0.088553</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.277957</td>\n",
              "      <td>-0.452603</td>\n",
              "      <td>-1.239624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.469999</td>\n",
              "      <td>-0.452603</td>\n",
              "      <td>2.080819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   num__Age  num__Work_Experience  num__Family_Size  cat__Gender_Female  \\\n",
              "0  0.318064             -0.452603         -0.575536                 0.0   \n",
              "1  2.582944             -0.756436         -0.575536                 0.0   \n",
              "2 -0.933580              1.674232          0.088553                 1.0   \n",
              "3 -0.277957             -0.452603         -1.239624                 1.0   \n",
              "4 -1.469999             -0.452603          2.080819                 0.0   \n",
              "\n",
              "   cat__Gender_Male  cat__Ever_Married_No  cat__Ever_Married_Yes  \\\n",
              "0               1.0                   0.0                    1.0   \n",
              "1               1.0                   0.0                    1.0   \n",
              "2               0.0                   1.0                    0.0   \n",
              "3               0.0                   0.0                    1.0   \n",
              "4               1.0                   0.0                    1.0   \n",
              "\n",
              "   cat__Graduated_No  cat__Graduated_Yes  cat__Profession_Artist  ...  \\\n",
              "0                0.0                 1.0                     0.0  ...   \n",
              "1                0.0                 1.0                     0.0  ...   \n",
              "2                0.0                 1.0                     0.0  ...   \n",
              "3                0.0                 1.0                     0.0  ...   \n",
              "4                1.0                 0.0                     0.0  ...   \n",
              "\n",
              "   cat__Spending_Score_Average  cat__Spending_Score_High  \\\n",
              "0                          0.0                       0.0   \n",
              "1                          0.0                       1.0   \n",
              "2                          0.0                       0.0   \n",
              "3                          1.0                       0.0   \n",
              "4                          0.0                       0.0   \n",
              "\n",
              "   cat__Spending_Score_Low  cat__Var_1_Cat_1  cat__Var_1_Cat_2  \\\n",
              "0                      1.0               0.0               0.0   \n",
              "1                      0.0               0.0               0.0   \n",
              "2                      1.0               0.0               0.0   \n",
              "3                      0.0               0.0               0.0   \n",
              "4                      1.0               0.0               0.0   \n",
              "\n",
              "   cat__Var_1_Cat_3  cat__Var_1_Cat_4  cat__Var_1_Cat_5  cat__Var_1_Cat_6  \\\n",
              "0               0.0               0.0               0.0               1.0   \n",
              "1               0.0               0.0               0.0               1.0   \n",
              "2               0.0               0.0               0.0               1.0   \n",
              "3               1.0               0.0               0.0               0.0   \n",
              "4               0.0               1.0               0.0               0.0   \n",
              "\n",
              "   cat__Var_1_Cat_7  \n",
              "0               0.0  \n",
              "1               0.0  \n",
              "2               0.0  \n",
              "3               0.0  \n",
              "4               0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine into a ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_features),\n",
        "    (\"cat\", cat_pipeline, cat_features)\n",
        "])\n",
        "\n",
        "# Applying the transformation\n",
        "X = df.drop(columns=[\"Segmentation\"])  # Features\n",
        "y = df[\"Segmentation\"]  # Target\n",
        "\n",
        "# Transforming the data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Convert processed data to a DataFrame\n",
        "X_processed_df = pd.DataFrame(X_processed, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "\n",
        "X_processed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9s56aFFxLfHd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.4841\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Full pipeline with preprocessing + classifier\n",
        "model_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Display results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXoCqMztjhr-"
      },
      "source": [
        "or create your own here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OoZ3oXEj2CW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Gender               0\n",
              "Ever_Married        84\n",
              "Age                  0\n",
              "Graduated           40\n",
              "Profession          79\n",
              "Work_Experience    562\n",
              "Spending_Score       0\n",
              "Family_Size        224\n",
              "Var_1               53\n",
              "Segmentation         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A3adbZXLfHe"
      },
      "source": [
        "# 4. Modeling and Validation\n",
        "\n",
        "Modelling is the process of building your own machine learning models to solve specific problems, or in this assignment context, predicting the probability for each class in the `Segmentation` feature. Validation is the process of evaluating your trained model using the validation set or cross-validation method and providing some metrics that can help you decide what to do in the next iteration of development.\n",
        "\n",
        "In this task, you are required to predict each class in the Segmentation feature using Ensemble Learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRWB1ua4pvYu"
      },
      "source": [
        "## 4.1 Ensemble\n",
        "\n",
        "Implement **at least 1 model** for each of the following learning algorithms:\n",
        "\n",
        "- Bagging\n",
        "- Boosting\n",
        "- Stacking\n",
        "- Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h49yUXXbqmfV"
      },
      "source": [
        "### 4.1.1 Bagging\n",
        "Bagging is a technique that trains a single type of model, with each model being trained on a different subset of the data. The final prediction is determined by the most frequently occurring prediction across all models. As a reference, you may use `RandomForestClassifier` to build your bagging model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh9n6lcqTyRI"
      },
      "outputs": [],
      "source": [
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jK7JcDorGpt"
      },
      "source": [
        "### 4.1.2 Boosting\n",
        "Boosting is a technique where the first model is trained on entire dataset, the second model to reduce the error of first model, followed by a third model to reduce the error of the second model, and so on. As a reference, you may use `GradientBoostingClassifier` to build your boosting model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_-RGnwJTxvR"
      },
      "outputs": [],
      "source": [
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJASP4uLrJoa"
      },
      "source": [
        "### 4.1.3 Voting\n",
        "Voting is a technique that trains multiple different models, with each model being trained on the entire dataset. The final prediction is obtained through voting. As a reference, you may use `VotingClassifier` to build your voting model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob1knKKxTw9Y"
      },
      "outputs": [],
      "source": [
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYQ0cYvrrNdI"
      },
      "source": [
        "### 4.1.4 Stacking\n",
        "Stacking is a technique that trains multiple different models, with each model being trained on the entire dataset. The final prediction is obtained through a meta-learner model that takes the predictions of the previous models as input. As a reference, you may use `StackingClassifier` to build your stacking model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvYuNxWcTwBe"
      },
      "outputs": [],
      "source": [
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVd0NkTLuwBY"
      },
      "source": [
        "Note: You can use/add other classifiers that haven't been mentioned, as long as it belong to one of the ensemble methods mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lPeNCJohenc"
      },
      "source": [
        "## 4.2 Validation\n",
        "\n",
        "Validation is the process of evaluating a trained model using a validation set or cross-validation method. It provides metrics that help determine the necessary steps for the next iteration of model development.  \n",
        "\n",
        "For validation, the metric used is **log loss**, which measures the model's performance in terms of probabilistic predictions. A lower log loss indicates better model calibration.  \n",
        "\n",
        "### Required Validation Results  \n",
        "The validation results that must be included in the notebook are:  \n",
        "1. The validation results from the required baseline models.  \n",
        "2. The validation results from the final submission model on **Kaggle**.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68IiNejlTuke"
      },
      "outputs": [],
      "source": [
        "# Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li4l53DjLfHh"
      },
      "source": [
        "## Submission\n",
        "To predict the test set target feature and submit the results to the kaggle competition platform, do the following:\n",
        "1. Create a new pipeline instance identical to the first in Data Preprocessing\n",
        "2. With the pipeline, apply `fit_transform` to the original training set before splitting, then only apply `transform` to the test set.\n",
        "3. Retrain the model on the preprocessed training set\n",
        "4. Predict the test set\n",
        "5. Make sure the submission contains the `ID`, `Segmentation` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LeqnfWc-LfHi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved at: output/submission.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure 'ID' column is retained for output\n",
        "df_test_id = df_test[[\"ID\"]]  # Keep the IDs for final output\n",
        "\n",
        "# Drop 'ID' column from test set before preprocessing\n",
        "X_test_final = df_test.drop(columns=[\"ID\"])\n",
        "\n",
        "# Apply the trained pipeline for transformation and prediction\n",
        "y_test_pred = model_pipeline.predict(X_test_final)\n",
        "\n",
        "# Create a DataFrame for submission\n",
        "df_submission = pd.DataFrame({\n",
        "    \"ID\": df_test_id[\"ID\"],\n",
        "    \"Segmentation\": y_test_pred\n",
        "})\n",
        "\n",
        "# Save as CSV file\n",
        "csv_filename = \"output/submission.csv\"\n",
        "df_submission.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Submission file saved at: {csv_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-jXvKOpLfHi"
      },
      "source": [
        "# 5. Error Analysis\n",
        "\n",
        "Based on all the process you have done until the modeling and evaluation step, write an analysis to support each steps you have taken to solve this problem. Write the analysis using the markdown block. Some questions that may help you in writing the analysis:\n",
        "\n",
        "1. Which segments (A, B, C, D) have the highest and lowest misclassification rates?\n",
        "2. Are there any specific segments where the model struggles to make correct predictions?\n",
        "3. Which features contribute the most to incorrect predictions?\n",
        "4. Which ensemble technique (Bagging, Boosting, Stacking, Voting) produces the lowest log loss?\n",
        "5. Are there significant differences in error distribution between different ensemble models?\n",
        "6. Does a particular model consistently misclassify certain segments more than others?\n",
        "7. etc.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWL3nEAELfHj"
      },
      "source": [
        "`Provide your analysis here`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
